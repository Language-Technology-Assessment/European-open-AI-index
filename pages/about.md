## What is the European Open-Source AI index?
The European Open-Source AI Index collects information on model openness, licensing, and EU regulation of generative AI systems and providers.

The index is a non-profit public resource hosted at the [Centre of Language and Speech Technology, Radboud University, The Netherlands](https://www.ru.nl/en/cls/clst), maintained by a small team of academics and community members.

## Founders

::person{image="/images/headshot-al.jpg" name="Andreas Liesenfeld"}
__Andreas Liesenfeld__ is co-founder of the index and Assistant Professor at Radboud University where he researches the societal and regulatory implications of emerging language technologies. His current work focuses on technology assessment, open source generative AI, and comparative AI regulation. At the Centre for Language Studies (CLS), Andreas Liesenfeld is a member of the language technology expertise group and, in collaboration with the Netherlands eScience center, develops open source research software for natural language processing.
::

::person{image="/images/headshot-md.png" name="Mark Dingemanse"}
__[Mark Dingemanse](https://markdingemanse.net "Mark Dingemanse")__ is co-founder of the EU OSAI index and Associate Professor at Radboud University. His current research looks at the intersection of language and technology, from the artisanal tools that people use in everyday conversation to the artificial techniques of large language models, voice user interfaces, and "AI". He directs the research programme _[Futures of Language](https://markdingemanse.net/futures "Futures of Language")_ funded by a VICI talent grant from the Dutch Research Council (2024-2029). 
::

## Researchers

::person{image="/images/headshot-db.jpg" name="Dick Blankvoort"}
__Dick Blankvoort__ is a student at Radboud University and a researcher at the Open Source AI Index. His primary interest lies in the field of Data Science, focusing both on the applications of generative AI and on their mathematical underpinnings. He is currently pursuing his internship at OSAI, as well as teaching a course on Computer Algebra.
::

::person{image="/images/headshot-nk.jpg" name="Nityaa Kalra"}
__Nityaa Kalra__  is a student at Radboud University and a researcher at the Open Source AI Index. Her interests lie in NLP, explainable AI, and building responsible AI systems. As part of her thesis, she is currently investigating bias in book recommender systems, examining how thematic and genre biases shape book recommendations. She has also been a teaching assistant for a course on Text and Multimedia Mining.
::

## Contributors

__Adem Kaya__

__Ada Lopez__

## Why is open-source AI important?
Open-source software and systems are a crucial building block of innovative technology ecosystems and provide an important alternative to proprietary, closed systems for users and builders of generative AI systems. True openness fosters innovation that not only serves commercial interests, but also contributes to knowledge access, free education, and a more informed public debate about this emerging technology.

## How is open-source AI regulated in the EU?
In 2025, the AI landscape will be shaken up by the enforcement of the EU AI Act, the world's first comprehensive AI law, with a projected impact comparable to GDPR. This regulation pays special attention to open-source systems and regulates ‘open’ systems differently. But the EU AI Act neither defines openness nor specifies how open-source licenses relate to openness. This work will be carried out by the future EU AI Office.

## What are the risks when the definition of ‘open’ is still open?
The unclear definition of openness in the domain of generative AI creates loopholes for overclaiming openness (by ie. using an open source license for a single aspect) and the risk of unintended claims to exemptions based on open-source status under EU law. A practice known as ‘open-washing’.

## How we evaluate openness
We created an evidence-based framework that distinguishes 14 dimensions of openness, from training datasets to scientific and technical documentation and from licensing to access methods. We published our research in a paper. The data is continuously updated and publicly available via our [GitHub repository](https://github.com/Language-Technology-Assessment/main-database). **Contributions are encouraged**. The website you’re currently reading is providing a user-friendly interface for the data from the Github repository and gives extra contextual information to a wider audience.

## Why did we do this?
Evidence-based openness assessment can help foster a generative AI landscape in which models can be effectively regulated, model providers can be held accountable, scientists can scrutinise generative AI, and end users can make informed decisions.

For scientific background on this project, check out these peer-reviewed papers:

- Liesenfeld, A., & Dingemanse, M. (2024). Rethinking open source generative AI: open-washing and the EU AI Act. _Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency_ (FAccT ’24). doi: [10.1145/3630106.3659005](https://dl.acm.org/doi/10.1145/3630106.3659005) 
- Liesenfeld, A., Lopez, A., & Dingemanse, M. (2023). Opening up ChatGPT: tracking openness, transparency, and accountability in instruction-tuned text generators. _CUI ’23: Proceedings of the 5th International Conference on Conversational User Interfaces_. doi: [10.1145/3571884.3604316](https://doi.org/10.1145/3571884.3604316)
- Solaiman, I. (2023). The Gradient of Generative AI Release: Methods and Considerations. _Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency_, 111–122. doi: [10.1145/3593013.3593981](https://doi.org/10.1145/3593013.3593981)
